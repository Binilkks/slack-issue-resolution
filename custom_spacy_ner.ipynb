{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f6323b7-a87a-44af-a646-0764679da109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at epoch 0: {'ner': 20.82686910778284}\n",
      "Losses at epoch 1: {'ner': 16.69800703972578}\n",
      "Losses at epoch 2: {'ner': 11.198690965771675}\n",
      "Losses at epoch 3: {'ner': 6.900807669837377}\n",
      "Losses at epoch 4: {'ner': 5.659683193676756}\n",
      "Losses at epoch 5: {'ner': 5.2499877011286245}\n",
      "Losses at epoch 6: {'ner': 4.629598415282388}\n",
      "Losses at epoch 7: {'ner': 4.671550753435833}\n",
      "Losses at epoch 8: {'ner': 4.327585416166888}\n",
      "Losses at epoch 9: {'ner': 3.19135602663606}\n",
      "Losses at epoch 10: {'ner': 3.5470724554981556}\n",
      "Losses at epoch 11: {'ner': 3.456577744064723}\n",
      "Losses at epoch 12: {'ner': 1.344206150816941}\n",
      "Losses at epoch 13: {'ner': 2.6949919164273424}\n",
      "Losses at epoch 14: {'ner': 1.4007487828570229}\n",
      "Losses at epoch 15: {'ner': 0.057181861126845965}\n",
      "Losses at epoch 16: {'ner': 0.006200338095895213}\n",
      "Losses at epoch 17: {'ner': 0.0674928022955809}\n",
      "Losses at epoch 18: {'ner': 0.00023445125119835606}\n",
      "Losses at epoch 19: {'ner': 0.0020612941175139144}\n",
      "[('raise', 'RAISE_INCIDENT')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training import Example\n",
    "import random\n",
    "\n",
    "# Load or create a blank English model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Add the NER pipeline if not already present\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\")\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Define custom labels\n",
    "labels = [\"RAISE_INCIDENT\", \"SEVERITY\"]\n",
    "for label in labels:\n",
    "    ner.add_label(label)\n",
    "\n",
    "# Training data\n",
    "TRAIN_DATA = [\n",
    "    (\"Please raise an incident with low priority\", {\"entities\": [(7, 12, \"RAISE_INCIDENT\"), (32, 45, \"SEVERITY\")]}),\n",
    "    (\"Raise an incident with high priority\", {\"entities\": [(0, 5, \"RAISE_INCIDENT\"), (26, 40, \"SEVERITY\")]}),\n",
    "    (\"Can you raise an incident with medium severity?\", {\"entities\": [(11, 16, \"RAISE_INCIDENT\"), (37, 53, \"SEVERITY\")]}),\n",
    "    (\"I need to raise an incident urgently\", {\"entities\": [(10, 15, \"RAISE_INCIDENT\")]}),\n",
    "    (\"Low priority incident request\", {\"entities\": [(0, 11, \"SEVERITY\")]}),\n",
    "]\n",
    "\n",
    "\n",
    "# Training the model\n",
    "optimizer = nlp.begin_training()\n",
    "for epoch in range(20):  # Adjust epochs as needed\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "        nlp.update([example], drop=0.5, losses=losses)\n",
    "    print(f\"Losses at epoch {epoch}: {losses}\")\n",
    "\n",
    "# Save the trained model\n",
    "nlp.to_disk(\"custom_ner_model\")\n",
    "\n",
    "# Load and test the model\n",
    "nlp_test = spacy.load(\"custom_ner_model\")\n",
    "doc = nlp_test(\"I need to raise an incident with high priority\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0582fa55-b410-4d78-9aa4-f859bde607a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Can you raise an incident with high priority?\n",
      "Entities: [('raise', 'RAISE_INCIDENT')]\n",
      "--------------------------------------------------\n",
      "Text: I need to raise an incident with low severity.\n",
      "Entities: [('raise', 'RAISE_INCIDENT')]\n",
      "--------------------------------------------------\n",
      "Text: Please raise an incident urgently.\n",
      "Entities: [('raise', 'RAISE_INCIDENT')]\n",
      "--------------------------------------------------\n",
      "Text: We should raise an incident with medium priority.\n",
      "Entities: [('raise', 'RAISE_INCIDENT')]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the trained model\n",
    "nlp = spacy.load(\"custom_ner_model\")\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"Can you raise an incident with high priority?\",\n",
    "    \"I need to raise an incident with low severity.\",\n",
    "    \"Please raise an incident urgently.\",\n",
    "    \"We should raise an incident with medium priority.\",\n",
    "]\n",
    "\n",
    "# Run the model on test sentences\n",
    "for sentence in test_sentences:\n",
    "    doc = nlp(sentence)\n",
    "    print(f\"Text: {sentence}\")\n",
    "    print(\"Entities:\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f3de981-5bff-4b24-b194-121d940dbd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"This is a minor incident, no rush\" with entities \"[(10, 15, 'RAISE_INCIDENT'), (0, 5, 'SEVERITY')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"We need to raise an urgent issue with critical sev...\" with entities \"[(12, 17, 'RAISE_INCIDENT'), (38, 55, 'SEVERITY')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at epoch 0: {'ner': 8.10111659905635}\n",
      "Losses at epoch 1: {'ner': 7.084617929857388}\n",
      "Losses at epoch 2: {'ner': 5.161716116481766}\n",
      "Losses at epoch 3: {'ner': 4.912617882944873}\n",
      "Losses at epoch 4: {'ner': 4.461441374509375}\n",
      "Losses at epoch 5: {'ner': 3.0150894767174394}\n",
      "Losses at epoch 6: {'ner': 3.2226783916058945}\n",
      "Losses at epoch 7: {'ner': 2.1753591153123533}\n",
      "Losses at epoch 8: {'ner': 1.6313980878460057}\n",
      "Losses at epoch 9: {'ner': 2.1831220831582967}\n",
      "Losses at epoch 10: {'ner': 2.7279622107577346}\n",
      "Losses at epoch 11: {'ner': 1.2412154031333962}\n",
      "Losses at epoch 12: {'ner': 1.873557252557273}\n",
      "Losses at epoch 13: {'ner': 0.6667160415836298}\n",
      "Losses at epoch 14: {'ner': 1.8510552962009914}\n",
      "Losses at epoch 15: {'ner': 0.5786519534742849}\n",
      "Losses at epoch 16: {'ner': 0.010881116991091956}\n",
      "Losses at epoch 17: {'ner': 0.022979086246307786}\n",
      "Losses at epoch 18: {'ner': 0.05992822017455302}\n",
      "Losses at epoch 19: {'ner': 0.003314179236776903}\n",
      "Losses at epoch 20: {'ner': 1.3218054983562953e-06}\n",
      "Losses at epoch 21: {'ner': 3.838623012106736e-05}\n",
      "Losses at epoch 22: {'ner': 0.00022305461682537708}\n",
      "Losses at epoch 23: {'ner': 1.6525001523875436e-05}\n",
      "Losses at epoch 24: {'ner': 2.7688089873372355e-05}\n",
      "Losses at epoch 25: {'ner': 8.389641468247932e-06}\n",
      "Losses at epoch 26: {'ner': 0.00041713586439419393}\n",
      "Losses at epoch 27: {'ner': 0.00015931934716780394}\n",
      "Losses at epoch 28: {'ner': 1.2194492731647352e-06}\n",
      "Losses at epoch 29: {'ner': 1.3509753816293797e-05}\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = [\n",
    "    (\"Please raise an incident with low priority\", {\"entities\": [(7, 12, \"RAISE_INCIDENT\"), (32, 45, \"SEVERITY\")]}),\n",
    "    (\"Raise an incident with high priority\", {\"entities\": [(0, 5, \"RAISE_INCIDENT\"), (26, 40, \"SEVERITY\")]}),\n",
    "    (\"Can you raise an incident with medium severity?\", {\"entities\": [(11, 16, \"RAISE_INCIDENT\"), (37, 53, \"SEVERITY\")]}),\n",
    "    (\"We need to raise an urgent issue with critical severity\", {\"entities\": [(12, 17, \"RAISE_INCIDENT\"), (38, 55, \"SEVERITY\")]}),\n",
    "    (\"Create a P1 ticket immediately\", {\"entities\": [(0, 6, \"RAISE_INCIDENT\"), (9, 11, \"SEVERITY\")]}),\n",
    "    (\"This is a minor incident, no rush\", {\"entities\": [(10, 15, \"RAISE_INCIDENT\"), (0, 5, \"SEVERITY\")]}),\n",
    "]\n",
    "for epoch in range(30):  # More training iterations\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "        nlp.update([example], drop=0.3, losses=losses)  # Reduced dropout\n",
    "    print(f\"Losses at epoch {epoch}: {losses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1ec3472-1c94-4251-8fcb-fb432c848627",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "    (\"Please raise an incident with low priority\", {\"entities\": [(7, 12, \"RAISE_INCIDENT\"), (32, 45, \"SEVERITY\")]}),\n",
    "    (\"Raise an incident with high priority\", {\"entities\": [(0, 5, \"RAISE_INCIDENT\"), (26, 40, \"SEVERITY\")]}),\n",
    "    (\"Can you raise an incident with medium severity?\", {\"entities\": [(11, 16, \"RAISE_INCIDENT\"), (37, 53, \"SEVERITY\")]}),\n",
    "    (\"We need to raise an urgent issue with critical severity\", {\"entities\": [(16, 21, \"RAISE_INCIDENT\"), (38, 55, \"SEVERITY\")]}),\n",
    "    (\"Create a P1 ticket immediately\", {\"entities\": [(0, 6, \"RAISE_INCIDENT\"), (8, 10, \"SEVERITY\")]}),\n",
    "    (\"This is a minor incident, no rush\", {\"entities\": [(17, 25, \"RAISE_INCIDENT\"), (10, 15, \"SEVERITY\")]}),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9c1a1b7-6d99-4e7d-8756-4d4219b9a67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Create a P1 ticket immediately\" with entities \"[(0, 6, 'RAISE_INCIDENT'), (8, 10, 'SEVERITY')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"We need to raise an urgent issue with critical sev...\" with entities \"[(16, 21, 'RAISE_INCIDENT'), (38, 55, 'SEVERITY')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"This is a minor incident, no rush\" with entities \"[(17, 25, 'RAISE_INCIDENT'), (10, 15, 'SEVERITY')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at epoch 0: {'ner': 3.9988747698200013}\n",
      "Losses at epoch 1: {'ner': 3.987170642404088}\n",
      "Losses at epoch 2: {'ner': 3.543748945272847}\n",
      "Losses at epoch 3: {'ner': 0.04853193992978255}\n",
      "Losses at epoch 4: {'ner': 0.023367843277183713}\n",
      "Losses at epoch 5: {'ner': 0.2523506871459097}\n",
      "Losses at epoch 6: {'ner': 0.9373315710503376}\n",
      "Losses at epoch 7: {'ner': 0.00022726879421584457}\n",
      "Losses at epoch 8: {'ner': 9.286503558716275e-05}\n",
      "Losses at epoch 9: {'ner': 0.04704331300059425}\n",
      "Losses at epoch 10: {'ner': 0.004840219012938343}\n",
      "Losses at epoch 11: {'ner': 0.0019221381661132318}\n",
      "Losses at epoch 12: {'ner': 1.2598549771596016e-07}\n",
      "Losses at epoch 13: {'ner': 1.184598691500723e-06}\n",
      "Losses at epoch 14: {'ner': 2.8848651362125242e-06}\n",
      "Losses at epoch 15: {'ner': 5.034795210151465e-07}\n",
      "Losses at epoch 16: {'ner': 1.7040698804080315e-05}\n",
      "Losses at epoch 17: {'ner': 6.766005691268563e-06}\n",
      "Losses at epoch 18: {'ner': 1.2049563155875185e-06}\n",
      "Losses at epoch 19: {'ner': 1.7815917733782335e-05}\n",
      "Losses at epoch 20: {'ner': 6.218156167650599e-05}\n",
      "Losses at epoch 21: {'ner': 1.1467992334964975e-06}\n",
      "Losses at epoch 22: {'ner': 8.016556401856201e-05}\n",
      "Losses at epoch 23: {'ner': 4.7857006896528965e-08}\n",
      "Losses at epoch 24: {'ner': 7.70914779145695e-07}\n",
      "Losses at epoch 25: {'ner': 0.0018057041652320184}\n",
      "Losses at epoch 26: {'ner': 1.8922689432188164e-07}\n",
      "Losses at epoch 27: {'ner': 7.414377202692706e-08}\n",
      "Losses at epoch 28: {'ner': 0.002237398994154747}\n",
      "Losses at epoch 29: {'ner': 5.455814542186594e-09}\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "        nlp.update([example], drop=0.3, losses=losses)\n",
    "    print(f\"Losses at epoch {epoch}: {losses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcdc213b-811d-4383-8eb8-b3d1681fdbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at epoch 0: {'ner': 6.299999475479126}\n",
      "Losses at epoch 1: {'ner': 6.15159398317337}\n",
      "Losses at epoch 2: {'ner': 5.980498731136322}\n",
      "Losses at epoch 3: {'ner': 5.748689711093903}\n",
      "Losses at epoch 4: {'ner': 5.63654488325119}\n",
      "Losses at epoch 5: {'ner': 5.431892931461334}\n",
      "Losses at epoch 6: {'ner': 4.987636029720306}\n",
      "Losses at epoch 7: {'ner': 4.639607608318329}\n",
      "Losses at epoch 8: {'ner': 4.096784889698029}\n",
      "Losses at epoch 9: {'ner': 3.669742077589035}\n",
      "Losses at epoch 10: {'ner': 2.9731157273054123}\n",
      "Losses at epoch 11: {'ner': 3.0054261088371277}\n",
      "Losses at epoch 12: {'ner': 2.4520759508013725}\n",
      "Losses at epoch 13: {'ner': 2.445624500513077}\n",
      "Losses at epoch 14: {'ner': 2.3663537837564945}\n",
      "Losses at epoch 15: {'ner': 2.4487969130277634}\n",
      "Losses at epoch 16: {'ner': 2.1282930753659457}\n",
      "Losses at epoch 17: {'ner': 1.7312833537580445}\n",
      "Losses at epoch 18: {'ner': 2.354266453854507}\n",
      "Losses at epoch 19: {'ner': 2.1607366295647807}\n",
      "Losses at epoch 20: {'ner': 2.1140032657567644}\n",
      "Losses at epoch 21: {'ner': 0.9136790928896517}\n",
      "Losses at epoch 22: {'ner': 1.2645687558106147}\n",
      "Losses at epoch 23: {'ner': 1.0837846550857648}\n",
      "Losses at epoch 24: {'ner': 0.5666947680583689}\n",
      "Losses at epoch 25: {'ner': 0.3447297364473343}\n",
      "Losses at epoch 26: {'ner': 0.21795936895068735}\n",
      "Losses at epoch 27: {'ner': 0.35776290530338883}\n",
      "Losses at epoch 28: {'ner': 0.04460177573491819}\n",
      "Losses at epoch 29: {'ner': 0.054793238723505056}\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = [\n",
    "    (\"Please raise an incident with low priority\", {\"entities\": [(7, 12, \"RAISE_INCIDENT\"), (30, 33, \"SEVERITY\")]})\n",
    "]\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# Add labels\n",
    "for label in [\"RAISE_INCIDENT\", \"SEVERITY\"]:\n",
    "    ner.add_label(label)\n",
    "\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "for epoch in range(30):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "        nlp.update([example], drop=0.3, losses=losses)\n",
    "    print(f\"Losses at epoch {epoch}: {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48514b8b-da7b-4489-89f9-3fa449c4ef2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Please raise an incident with high priority\n",
      "Entities: [('raise', 'RAISE_INCIDENT'), ('high', 'SEVERITY')]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test sentences\n",
    "test_sentences = [\n",
    "\"Please raise an incident with high priority\"\n",
    "]\n",
    "\n",
    "# Run the model on test sentences\n",
    "for sentence in test_sentences:\n",
    "    doc = nlp(sentence)\n",
    "    print(f\"Text: {sentence}\")\n",
    "    print(\"Entities:\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a07f435-af3e-492e-9897-537b67bf80bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('raise', 'RAISE_INCIDENT'), ('high', 'SEVERITY')]\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "nlp.to_disk(\"custom_ner_model\")\n",
    "\n",
    "# Load and test the model\n",
    "nlp_test = spacy.load(\"custom_ner_model\")\n",
    "doc = nlp_test(\"I need to raise an incident with high priority\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10c833-0e5a-4a23-9557-7e32fbf3d1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
